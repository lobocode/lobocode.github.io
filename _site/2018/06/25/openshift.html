<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>OpenShift - lobocode - Labs</title>
        <meta name="viewport" content="width=device-width">

        <meta name="description"
              content="Rants about programming, open source, caffeine, unfunny
              jokes and such stuff." >
        <meta name="keywords"
              content="programming, open source, javascript, python,
              functional programming, clean code junkie">

        <link href="/atom.xml"
              rel="alternate"
              title="lobocode - DevOps"
              type="application/atom+xml" />

        <!-- syntax highlighting CSS -->
        <link rel="stylesheet" href="/css/syntax.css">

        <!-- Custom CSS -->
        <link rel="stylesheet" href="/media/css/screen.css">

    </head>
    <body>

      <div id="header">
        <header id="logo">
          <h1>
            <a href="/">Lobocode Labs</a>
            <em>SRE, labs, sharing knowledge...</em>
          </h1>
        </header>
        <nav id="top-navigation">
          <ul>

			
                
                
              <li><a class="active" href="/index.html">Home</a></li>
            
                
                
              <li><a class="" href="/about/index.html">About</a></li>
            
                
                
              <li><a class="" href="/projects/index.html">Projects</a></li>
            
          </ul>
        </nav>
      </div>

      <div id="content">
        <div id="content-wrapper">
          <header class="page-heading">
	<h2 class="page-title">OpenShift</h2>
	<p class="meta published-date">Published 25 June 2018</p>
	<h3 class="page-snip">Arrumando a casa</h3>
</header>

<div id="post">
	<blockquote>
  <p>Este é um material que fora elaborado com o propósito de compreender melhor o funcionamento do OpenShift, e de plataformas agregadas. Se houver por minha parte alguma informação errada, por favor, entre em contato ou me mande um pull request no github. As referências usadas para o estudo além da experiência prática, estarão no rodapé da página. Artigo em constante atualização e revisão.</p>
</blockquote>

<hr />

<h4 id="capÍtulo-1---o-conceito">CAPÍTULO 1 - O CONCEITO</h4>

<ul>
  <li><strong><a href="#breve-introducao">Breve introdução</a></strong></li>
  <li><strong><a href="#plataforma-em-conteineres">Plataforma em contêineres</a></strong></li>
  <li><strong><a href="#casos-de-uso">Casos de Uso</a></strong></li>
  <li><strong><a href="#escalonando-aplicacoes">Escalonando Aplicações</a></strong></li>
</ul>

<h4 id="capÍtulo-2---getting-started">CAPÍTULO 2 - GETTING STARTED</h4>

<ul>
  <li><strong><a href="#instalando-o-openshift">Instalando o OpenShift</a></strong></li>
  <li><strong><a href="#configurando-o-networkmanager">Configurando o NetworkManager</a></strong></li>
  <li><strong><a href="#instalando-ferramentas-no-servidor-master">Instalando ferramentas no servidor master</a></strong></li>
  <li><strong><a href="#configurando-o-conteiner-storage">Configurando o conteiner storage</a></strong></li>
</ul>

<h4 id="capÍtulo-3---wip">CAPÍTULO 3 - WIP</h4>
<ul>
  <li><strong><a href="#acessando-seu-cluster-e-efetuando-login">Acessando seu cluster e efetuando login</a></strong></li>
  <li><strong><a href="#criando-projetos-e-implementando-aplicativos">Criando projetos e implementando aplicativos</a></strong></li>
  <li><strong><a href="#acessando-sua-aplicacao-criando-rotas">Acessando sua aplicação criando rotas</a></strong></li>
  <li><strong><a href="#investigando-componentes-da-aplicacao">Investigando componentes da aplicação</a></strong></li>
  <li><strong><a href="#comparando-linha-de-comando-com-fluxo-de-trabalho-web">Comparando linha de comando com fluxo de trabalho web</a></strong></li>
</ul>

<hr />

<h3 id="breve-introducao">BREVE INTRODUCAO</h3>

<p>Devido ao crescimento da demanda por máquinas virtuais e grande dificuldade na operação desse ambiente, surgiu a necessidade de melhorar esse modelo. Com isso empresas que buscam melhores soluções para administradores de sistemas, e desenvolvedores tanto do meio corporativo, quanto da própria comunidade, perceberam que não havia a necessidade de recriar um sistema complexo bastando apenas reutilizar alguns recursos da própria arquitetura e engenharia do kernel Linux.</p>

<p>Lançando mão de uma funcionalidade nativa do Kernel Linux para facilitar a criação e gestão destes ambientes virtuais, eles conseguiram ótimos resultados. Assim surgiu o <strong><a href="https://en.wikipedia.org/wiki/LXC">LXC</a></strong>.</p>

<p><img src="https://i.imgur.com/ycHhkfb.png" alt="https://i.imgur.com/ycHhkfb.png" /></p>

<p>O Linux Container ou <strong><a href="https://en.wikipedia.org/wiki/LXC">LXC</a></strong> como é mais conhecido, foi lançado em 2008 e é uma tecnologia que permite a criação de múltiplas instâncias isoladas de um determinado Sistema Operacional dentro de um único host. É uma maneira de virtualizar aplicações dentro de um servidor Linux. O conceito é simples e antigo sendo o comando <strong><a href="https://en.wikipedia.org/wiki/Chroot">chroot</a></strong> seu precursor mais famoso que foi lançado em 1979 pelo <strong><a href="https://en.wikipedia.org/wiki/Version_7_Unix">Unix V7</a></strong> com o intuito de segregar acessos a diretórios e evitar que o usuário pudesse ter acesso à estrutura raiz (“/” ou root). Esse conceito evoluiu alguns anos mais tarde com o lançamento do <strong><a href="https://www.freebsd.org/cgi/man.cgi?query=jail&amp;sektion=8&amp;manpath=freebsd-release-ports">jail</a></strong>, no sistema operacional FreeBSD 4.</p>

<p>Essa implementação já introduzia a ideia de segregação de rede e limitação dos acessos de superusuários aos processos que passou a ser adotada com maiores funcionalidades pelas distribuições Linux. Posteriormente foi melhor definido em alguns sistemas como o <strong><a href="https://en.wikipedia.org/wiki/Workload_Partitions">AIX WPAR</a></strong> e o <strong><a href="https://en.wikipedia.org/wiki/Solaris_Containers">Solaris Containers</a></strong>. Nesses dois sistemas já havia o conceito de virtualização de sistema operacional, mas não o conceito de contêineres.</p>

<p>Nas distribuições Linux o chroot era uma maneira fácil de criar uma jail para as conexões dos servidores FTP, mas acabou ficando mais conhecido pela sua vulnerabilidade do que pela sua segurança. Mais tarde o chroot acabou ajudando a cunhar um termo <strong><a href="https://pt.wikipedia.org/wiki/Jailbreak_(iOS)">jailbreak</a></strong>.</p>

<p>A grande diferença entre o chroot e o LXC é o nível de segurança que se pode alcançar. Com relação à virtualização, a diferença está no fato do LXC não necessitar de uma camada de sistema operacional para cada aplicação. Ao comparar com a virtualização tradicional, fica mais claro que uma aplicação sendo executada em um LXC demanda muito menos recursos, consumindo menos espaço em disco, e com um nível de portabilidade difícil de ser alcançado por outras plataformas.</p>

<p>Mas não foi só a adoção de desenvolvedores e administradores de sistemas que tornou essa tecnologia tão popular. A consolidação da virtualização no mercado e a crescente demanda por computação em nuvem criaram o ambiente perfeito para o LXC se espalhar rapidamente. Aplicações podem ser portadas direto do laptop do desenvolvedor, para o servidor de produção, ou ainda para uma instância virtual em uma nuvem pública ou privada.</p>

<p><img src="https://i.imgur.com/6zqz4UI.png" alt="https://i.imgur.com/6zqz4UI.png" /></p>

<p>Hoje um dos mais conhecidos LXC’s do mercado é o <strong><a href="https://pt.wikipedia.org/wiki/Docker_(programa)">Docker</a></strong>, escrito em <strong><a href="https://golang.org/">GO</a></strong>, que nasceu como um projeto open source da <strong><a href="https://cloud.docker.com/">DotCloud</a></strong>, uma empresa de <strong><a href="https://pt.wikipedia.org/wiki/Plataforma_como_servi%C3%A7o">PaaS (Platform as a Service)</a></strong> que apesar de estar mais interessada em utilizar LXC apenas em suas aplicações, acabou desenvolvendo um produto que foi muito bem aceito pelo mercado.</p>

<p>Do ponto de vista de desenvolvimento, o Docker por sí atendeu muito bem em vários quesitos. No entanto, com a crescente demanda e necessidade de entregar mais resultados em menos tempo, surgiu também a necessidade de extender as funcionalidades do Docker. Surgiu então ferramentas de orquestração de contêineres como Kubernetes e posteriormente potencializadores do próprio Kubernetes como é o caso do OpenShift.</p>

<hr />

<h3 id="plataforma-em-conteineres">PLATAFORMA EM CONTEINERES</h3>

<p><strong>O que é uma plataforma de contêineres?</strong></p>

<p>Trata-se de uma plataforma que usa contêineres para gerar build, deploy, servir e orquestrar os aplicativos em execução dentro dele. Os contêineres contém todas as bibliotecas e códigos necessários para que as aplicações funcionem adequadamente e de maneira isolada. Existem basicamente, cinco tipos de recursos são isolados em contêineres. São eles:</p>

<ul>
  <li>Sistemas de arquivos montados.</li>
  <li>Recursos de memória compartilhada.</li>
  <li>Nome do host e nome de domínio.</li>
  <li>Recursos de rede (endereço IP, endereço MAC, buffers de memória).</li>
  <li>Contadores de processo.</li>
</ul>

<p>Embora o docker engine gerencie contêineres facilitando os recursos do kernel do Linux, ele é limitado a um único sistema operacional no host. Para orquestrar contêineres em vários servidores com eficiência, é necessário usar um mecanismo de orquestração de contêineres. Isto é, um aplicativo que gerencia contêineres em tempo de execução em um cluster de hosts para fornecer uma plataforma de aplicativo escalonável.</p>

<p>Existem alguns orquestradores conhecidos na comunidade e no mercado como o Rancher, Heroku, Apache Mesos, Docker Swarm, Kubernetes e o OpenShift. O <strong><a href="https://www.openshift.com/">OpenShift</a></strong> usa o <strong><a href="https://kubernetes.io">Kubernetes</a></strong> como seu mecanismo de orquestração de contêineres. O Kubernetes é um projeto de código aberto que foi iniciado pelo Google. Em 2015, foi doado para a <strong><a href="http://www.cncf.io">Cloud Native Computing Foundation</a></strong>.</p>

<p>O Kubernetes emprega uma arquitetura master/node. Os servidores master do Kubernetes mantêm as informações sobre o cluster de servidores e os nodes executam as cargas de trabalho reais do aplicativo. A grande vantagem de usar o OpenShift ao invés de seu concorrente Heroku, é que o OpenShift é gratuito, de código aberto, e roda tanto em rede pública, quanto em rede privada. O Heroku roda em plataforma fechada e somente em redes públicas. A baixo uma visão geral da arquitetura do Kubernetes:</p>

<p><img src="https://i.imgur.com/2wzeZJt.png" alt="https://i.imgur.com/2wzeZJt.png" /></p>

<p>Para tirar proveito de todo o potencial de uma plataforma de contêiner como o Kubernetes, é necessário alguns componentes adicionais. O OpenShift usa o docker e o Kubernetes como ponto de partida e adiciona mais algumas ferramentas para proporcionar uma melhor experiência aos usuários. O OpenShift usa a arquitetura master/node do Kubernetes e partir daí, se expande para fornecer serviços adicionais.</p>

<p>Em uma plataforma de contêiner como o OpenShift, as imagens são criadas quando ocorre o deploy das aplicações, ou quando as imagens são atualizadas. Para ser eficaz, as imagens devem estar disponíveis rapidamente em todos os nodes em um cluster. Para tornar isto possível, o OpenShift inclui um registro de imagens integrado como parte de sua configuração padrão. O registro de imagem é um local central que pode servir imagens dos contêineres para vários locais (tipo um <strong><a href="https://hub.docker.com/">DockerHub</a></strong> local).</p>

<p>No Kubernetes, os contêineres são criados nos nodes usando componentes chamados <strong>pods</strong>. Os pods são a menor unidade dentro de um cluster Kubernetes e nada mais é do que containers rodando dentro do seu cluster. Quando um aplicativo consiste em mais de um pods, o acesso ao aplicativo é gerenciado por meio de um componente chamado service.</p>

<p>Um service é um proxy que conecta vários pods e os mapeia para um endereço IP em um ou mais nodes no cluster. Os endereços IP podem ser difíceis de gerenciar e compartilhar, especialmente quando estão por trás de um firewall. O OpenShift ajuda a resolver esse problema fornecendo uma camada de roteamento integrada. A camada de roteamento é um software balanceador de carga.</p>

<p>Quando é feito um deploy de uma aplicação no OpenShift, um registro DNS é criado automaticamente para ele. Esse registro DNS é adicionado ao balanceador de carga, e o balanceador de carga faz interface com o serviço Kubernetes para lidar eficientemente com as conexões entre o deploy da aplicação e seus usuários. Dessa forma, não interessa saber o IP do pod uma vez que quando o container for derrubado e subir outro contêiner para substituí-lo, haverá outro IP em seu lugar.</p>

<p>Nesse caso o registro DNS que fora criado automaticamente será nosso mapeamento de rede daquela respectiva aplicação. Com as aplicações sendo executadas em pods em vários nodes e solicitações de gerenciamento vindas do node master, há bastante comunicação entre os servidores em um cluster do OpenShift. Assim, você precisa ter certeza de que o tráfego está corretamente criptografado e que poderá separar quando necessário. Visão geral da arquitetura OpenShift:</p>

<p><img src="https://i.imgur.com/o3uoJ12.png" alt="https://i.imgur.com/o3uoJ12.png" /></p>

<p>O OpenShift usa uma solução de rede definida por software <strong><a href="https://pt.wikipedia.org/wiki/Software_defined_networking">SDN</a></strong> para criptografar e modelar o tráfego de rede em um cluster. O OpenShift SDN, é uma solução que usa o <strong><a href="http://openvswitch.org">Open vSwitch</a></strong> e outras tecnologias software livre, que são configuradas por padrão quando o OpenShift é implementado. Outras soluções SDN também são suportadas.</p>

<p>O OpenShift possui fluxos de trabalho projetados para ajudá-lo a gerenciar seus aplicativos em todas as fases de seu ciclo de vida:</p>

<ul>
  <li>
    <p><strong>Build</strong></p>

    <ul>
      <li>A principal maneira de criar aplicativos no OpenShift é usando <code class="highlighter-rouge">build image</code>. Esse processo é o fluxo de trabalho padrão.</li>
    </ul>
  </li>
  <li>
    <p><strong>Deployment</strong></p>

    <ul>
      <li>No fluxo de trabalho padrão no OpenShift, o deployment da aplicação é acionado automaticamente depois que a imagem do contêiner é criado e disponibilizado. O processo de deployment usa a imagem do aplicativo recém criado e a implanta em um ou mais nodes. Além dos pods dos aplicativos, um serviço é criado, junto com uma rota de DNS na camada de roteamento.</li>
    </ul>
  </li>
</ul>

<p><img src="https://i.imgur.com/tl53ec9.png" alt="https://i.imgur.com/tl53ec9.png" /></p>

<ul>
  <li>
    <p><strong>Upgrade</strong></p>

    <ul>
      <li>Os usuários podem acessar o aplicativo recém-criado através da camada de roteamento após todos os componentes terem sido implantados. As atualizações de aplicativos usam o mesmo fluxo de trabalho. Quando um upgrade é acionado, uma nova imagem de contêiner é criada e a nova versão do aplicativo é implantada. Vários processos de atualização estarão disponíveis. A baixo a visão geral do processo de deploy da aplicação:<img src="https://i.imgur.com/aGhInY5.png" alt="https://i.imgur.com/aGhInY5.png" /></li>
    </ul>
  </li>
</ul>

<p>É assim que o OpenShift funciona em alto nível. Para obter uma lista mais abrangente de como o OpenShift se integra e
expande as funcionalidades do Kubernetes, visite <strong><a href="http://www.openshift.com/container-platform/kubernetes.html">www.openshift.com/container-platform/kubernetes.html</a></strong>.</p>

<ul>
  <li>Retirement (fim do ciclo de vida).</li>
</ul>

<hr />

<h3 id="casos-de-uso">CASOS DE USO</h3>

<p>Se parar-mos para refletir um pouco sobre tecnologias que vieram com a proposta de isolar processos e serviços como os mainframes, e a revolução da virtualização onde várias máquinas virtuais podem ser executadas em um único servidor físico, podemos compreender melhor o rumo em que as tecnologias hoje tem avançado.</p>

<p>Por exemplo, com máquinas virtuais, cada processo é isolado em sua própria máquina virtual. Como cada máquina virtual possui um sistema operacional completo e um kernel completo, ele deve ter todos os sistemas de arquivos necessários para um sistema operacional completo. Isso também significa que ele deve ser corrigido, gerenciado e tratado como uma infraestrutura tradicional. Contêineres são o próximo passo nessa evolução. Um contêiner contém tudo o que a aplicação precisa para rodar com sucesso. Como por exemplo:</p>

<ul>
  <li>Código-fonte ou o código compilado</li>
  <li>Bibliotecas e aplicativos necessários para rodar corretamente</li>
  <li>Configurações e informações sobre como conectar-se a fontes de dados compartilhadas</li>
</ul>

<p>Máquinas virtuais podem ser usadas para isolamento do processo:</p>

<p><img src="https://i.imgur.com/FsyZT7m.png" alt="https://i.imgur.com/FsyZT7m.png" /></p>

<p>Casos de uso para plataformas que trabalham com contêineres:</p>

<p><img src="https://i.imgur.com/MTIhnmV.png" alt="https://i.imgur.com/MTIhnmV.png" /></p>

<p>Os contêineres usam um único kernel para servir aplicações economizando espaço, e recursos e fornecendo plataformas de aplicações flexíveis. No entanto, é bom frizar que <strong>o que os contêineres não contêm, é igualmente importante</strong>. Ao contrário das máquinas virtuais, todos os contêineres são executados em um único kernel Linux compartilhado.</p>

<p>Para isolar os aplicativos, os contêineres usam componentes dentro do kernel. Como os contêineres não precisam incluir um kernel completo para atender a aplicação a ser implementada, além de todas as dependências de um sistema operacional, eles tendem a ser muito menores do que as máquinas virtuais, tanto em suas necessidades de armazenamento, quanto no consumo de recursos.</p>

<p>Por exemplo, enquanto uma máquina virtual típica você poderá começar com um storage de 10 GB mais ou menos, a imagem do contêiner do CentOS 7 é de 140 MB (do Alpine Linux é ainda menor). Ser menor vem com algumas vantagens: Primeiro, a portabilidade é aprimorada. Mover 140 MB de um servidor para outro é muito mais rápido do que mover 10 GB ou mais. Em segundo lugar, iniciar um contêiner não inclui a inicialização de um kernel inteiro, o processo de inicialização é muito mais rápido. Iniciar um contêiner é normalmente medido em milissegundos, ao contrário de segundos ou minutos para máquinas virtuais.</p>

<p>As tecnologias por trás dos contêineres fornecem vários benefícios técnicos. Eles também oferecem vantagens comerciais. Soluções empresariais modernas devem incluir economia de tempo ou recursos como parte de seu design. Se você comparar um servidor que usa máquinas virtuais para isolar processos com um que usa contêineres para fazer o mesmo, notará algumas diferenças fundamentais:</p>

<ul>
  <li>Os contêineres consomem os recursos do servidor com mais eficiência. Como há um único kernel compartilhado para todos os contêineres em um host, em vez de vários kernels virtualizados, como em máquinas virtuais, mais recursos do servidor são usados para fornecer aplicações, em vez de haver sobrecarga na plataforma.</li>
  <li>A densidade da aplicação aumenta com os contêineres. Como a unidade básica usada para efetuar o deploy da aplicação (imagens de contêiner) é muito menor que a unidade para máquinas virtuais (imagens de máquina virtual), mais aplicativos podem caber por servidor. Isso significa que mais aplicações exigem menos servidores para serem executados.</li>
</ul>

<p>Comparando máquinas virtuais e contêineres, podemos ver, por exemplo, que os contêineres fornecem uma melhor utilização dos recursos do servidor:</p>

<p><img src="https://i.imgur.com/IP1wCV7.png" alt="https://i.imgur.com/IP1wCV7.png" /></p>

<p>No entanto, mesmo que os contêineres sejam ótimas ferramentas, nem sempre são a melhor ferramenta para todos os trabalhos. Por exemplo, se você tiver um aplicativo legado complexo, tenha cuidado ao decidir dividi-lo e convertê-lo em uma série de contêineres. Se a aplicação em questão trata-se de um modelo monolítico muito grande, e com diversos recursos, com um banco de dados relacional enorme, e esta aplicação fizer parte de todo um ecossistema de outras aplicações onde compartilha recursos, executa-lo em um contêiner não fará muito sentido e poderá ser um desafio bastante cansativo de tentar implementa-lo em contêineres.</p>

<p>Os contêineres são uma tecnologia revolucionária, <strong>mas não fazem tudo por conta própria</strong>. O armazenamento é uma área em que os contêineres precisam ser configurados com outras soluções para efetuar deploys em produção, por exemplo. Isso ocorre porque o armazenamento criado quando um contêiner é levantado, é efêmero. Isto é, se um contêiner for destruído ou substituído, o armazenamento de dentro desse contêiner não será reutilizado.</p>

<p>Isso é proposital e ocorre por design para permitir que os contêineres estejam sempre stateless por padrão. Isto é, se algo der errado, um container pode ser removido completamente do seu ambiente, e um novo pode ser colocado para substituí-lo quase que instantaneamente. Em outras palavras, <strong>contêineres foram feitos para morrer</strong>. A idéia de um contêiner stateless é ótima. Mas em algum lugar em sua aplicação, geralmente em vários lugares, os dados precisam ser compartilhados em vários contêineres, e o estado do serviço precisa ser preservado. Aqui estão alguns exemplos dessas situações:</p>

<ul>
  <li>Dados compartilhados que precisam estar disponíveis em vários contêineres, como imagens carregadas para um aplicativo da web.</li>
  <li>Informações do estado do usuário em um aplicativo complexo, que permite que os usuários continuem de onde pararam durante uma transação de longa duração.</li>
  <li>Informações armazenadas em bancos de dados relacionais ou não relacionais.</li>
</ul>

<p>Em todas essas situações e muitas outras, você precisa ter <strong>armazenamento persistente disponível em seus contêineres</strong>. Esse armazenamento deve ser definido como parte do deploy da sua aplicação e deve estar disponível em todos os nodes do cluster no OpenShift. Felizmente, o OpenShift tem várias maneiras de resolver esse problema. Quando você consegue integrar efetivamente o armazenamento compartilhado aos contêineres da sua aplicação, poderá pensar em escalabilidade.</p>

<hr />

<h3 id="escalonando-aplicacoes">ESCALONANDO APLICACOES</h3>

<p>Para aplicações stateless, escalar para cima e para baixo é simples. Como não há dependências além do que está no contêiner e como as transações que acontecem no contêiner são atômicas por design, tudo o que você precisa fazer para dimensionar uma aplicação stateless, é implantar mais instâncias dele e equilibrá-las. Para tornar esse processo ainda mais fácil, o OpenShift faz o proxy das conexões para cada aplicativo por meio de um balanceador de carga integrado. Isso permite que os aplicativos aumentem e diminuam o escalonamento sem alteração na maneira como os usuários se conectam a aplicação.</p>

<p>Se seus aplicativos forem stateful, o que significa que eles precisam armazenar ou recuperar dados compartilhados, como um banco de dados ou dados que um usuário carregou, então você precisará fornecer armazenamento persistente para eles. Esse armazenamento precisa ser ampliado e reduzido automaticamente em suas aplicações no OpenShift. Para aplicações com informações de estado, o armazenamento persistente é um componente-chave que deve ser totalmente integrado ao seu design.</p>

<p>À medida que você começa a separar os aplicativos tradicionais e monolíticos em serviços menores que funcionam de forma eficaz em contêineres, você começará a visualizar suas necessidades de dados de uma maneira diferente. Esse processo é geralmente chamado de design de aplicativos como microsserviços. Integrando aplicativos stateful e stateless:</p>

<p><img src="https://i.imgur.com/cG69vhp.png" alt="https://i.imgur.com/cG69vhp.png" /></p>

<p>O OpenShift pode integrar e gerenciar plataformas de armazenamento externo e garantir que o volume de armazenamento de melhor ajuste seja correspondido com os aplicativos que precisam dele. Para qualquer aplicação, você terá serviços que precisam ser informativos e outros sem estado. Por exemplo, o serviço que fornece conteúdo da web estático pode ser sem estado, enquanto o serviço que processa a autenticação do usuário precisa poder gravar informações no armazenamento persistente.</p>

<p>Como cada serviço é executado em seu próprio contêiner, os serviços podem ser ampliados e desativados independentemente. Em vez de precisar ampliar toda a sua base de código, com os contêineres, você dimensiona apenas os serviços em seu aplicativo que precisam processar cargas de trabalho adicionais. Além disso, como apenas os contêineres que precisam de acesso ao armazenamento persistente o contêm, os dados que entram no contêiner são mais seguros.</p>

<p>No exemplo abaixo, se houvesse uma vulnerabilidade no serviço B, um processo comprometido teria dificuldade em obter acesso aos dados armazenados no armazenamento persistente. Ilustrandoas diferenças entre aplicativos tradicionais e de microsserviço: os aplicativos de microsserviço escalonam seus componentes de forma independente, criando melhor desempenho e utilização de recursos:</p>

<p><img src="https://i.imgur.com/8sPOhGu.png" alt="https://i.imgur.com/8sPOhGu.png" /></p>

<p>Isso nos leva ao fim do nosso passo inicial inicial do OpenShift e como ele implementa, gerencia e orquestra os aplicativos implantados com contêineres usando o docker e o Kubernetes. Osbenefícios fornecidos pelo OpenShift economizam tempo para humanos e usam os recursos do servidor com mais eficiência. Além disso, a natureza de como os contêineres funcionam oferece melhor escalabilidade e velocidade de implantação em relação às implantações de máquinas virtuais.</p>

<hr />

<h4 id="instalando-o-openshift">INSTALANDO O OPENSHIFT</h4>

<p>Para este artigo, usarei a distribuição GNU/Linux Centos 7. Ele pode ser executado em servidores físicos, máquinas virtuais (VMs) ou VMs em uma nuvem pública, como o Amazon Web Services (AWS) EC2 ou Google Cloud. Essa instalação deve levar aproximadamente uma hora, dependendo da velocidade da sua conexão com a Internet.</p>

<p>Na maior parte do tempo configurando o OpenShift, darei ênfase à linha de comando para controlar o cluster. Para instalar o <code class="highlighter-rouge">oc</code>, você precisará ser super usuário, ou ter acesso ao <strong>root</strong>. Para compreender melhor do que se trata o comando <code class="highlighter-rouge">oc</code>, recomendo acessar <strong><a href="https://github.com/openshift/origin/blob/master/docs/cli.md">https://github.com/openshift/origin/blob/master/docs/cli.md</a></strong> documentação completa do comando <code class="highlighter-rouge">oc</code>. A configuração padrão do OpenShift usa a porta <strong>TCP 8443</strong> para acessar a API, e a interface Web. Acessaremos o servidor master nessa porta.</p>

<p>Para garantir que o cluster possa se comunicar adequadamente, várias portas TCP e UDP precisam estar abertas no master e nos nodes. Você poderá encontrar mais detalhes em <strong><a href="https://docs.openshift.org/3.6/install_config/install/prerequisites.html#required-ports">https://docs.openshift.org/3.6/install_config/install/prerequisites.html#required-ports</a></strong>. Em nosso caso, faremos isto de maneira mais simples. Por exemplo, caso você esteja criando este ambiente uma rede isolada, como em seu laptop, poderá deixar todas as portas abertas. Ou se preferir, abaixo uma lista de portas que usaremos inicialmente:</p>

<p><img src="https://i.imgur.com/SH20A4i.png" alt="https://i.imgur.com/SH20A4i.png" /></p>

<p>No OpenShift, os hostnames para todos os nodes devem ter um registro DNS. Isso permite que o tráfego criptografado rede entre os nodes funcione corretamente. Basicamente você precisará configurar um <strong><a href="https://tools.ietf.org/html/rfc4592">registro DNS curinga</a></strong> que apontará para o seu cluster afim de acessar os aplicativos que você implementar futuramente.</p>

<p>Se você já tem um servidor DNS já resolve a questão. Caso contrário, você poderá usar o domínio <strong><a href="nip.io">nip.io</a></strong>.</p>

<blockquote>
  <p>NOTA: Se você tem experiência com servidores Linux, poderá estar se perguntando: “Por que não posso simplesmente usar o arquivo <code class="highlighter-rouge">/etc/hosts</code> para este fim? A resposta é bem simples: esta configuração só funcionaria bem em um host pois não há propagação do DNS na rede. Serviria bem para um Minishift por exemplo. Mas para clusters distribuídos, o melhor é ter um DNS propagado.</p>
</blockquote>

<p>O domínio <strong><a href="http://nip.io/">nip.io</a></strong> quebra um galho enorme neste aspecto. Em vez de configurar e gerenciar um servidor DNS, você poderá criar registros DNS que resolvam qualquer endereço IP escolhido.</p>

<p>A única desvantagem do <strong><a href="http://nip.io/">nip.io</a></strong> em comparação ao um servidor DNS próprio, é que você dependerá do acesso á Internet. O único requisito para nossa instalação, no entanto, é que todos os seus servidores possam acessar um servidor DNS público. Como tenho que escolher qual DNS usarei para este artigo, então, escolhi usar o <strong><a href="http://nip.io/">nip.io</a></strong>.  A baixo, um exemplo do que poderemos configurar como modelo:</p>

<p><img src="https://i.imgur.com/LKIgIoQ.png" alt="https://i.imgur.com/LKIgIoQ.png" /></p>

<p>O CentOS 7 com o OpenShift terá endereço IP estático para garantir que o DNS e os hostnames configurados funcionem de maneira consistente. Se você não usasse endereço IP estático, seria necessário gerenciar um servidor DHCP em seu ambiente o que de todo modo não é uma boa prática.</p>

<blockquote>
  <p>NOTA: O servidor DNS que estamos usando é o 8.8.8.8, que é um dos servidores DNS públicos do Google. Você pode usar qualquer servidor DNS que desejar, mas, para funcionar, ele deve resolver consultas DNS públicas para o domínio nip.io.</p>
</blockquote>

<p>Consulte os <strong><a href="https://docs.openshift.org/3.6/install_config/install/prerequisites.html#system-requirements">requisitos oficiais de hardware</a></strong> para a instalação do OpenShift Origin. Eles são baseados na premissa de que você montará um cluster grande em produção. Em nosso caso, vamos testar algo menor:</p>

<p><img src="https://i.imgur.com/qAChvCm.png" alt="https://i.imgur.com/qAChvCm.png" /></p>

<p>Agora como já vimos como preparar o ambiente, vamos à primeira etapa de instalação do OpenShift. Primeiro, vamos instalar o repositório <strong><a href="">Extra Packages for Enterprise Linux - EPEL</a></strong> e em seguida o OpenShift Origin. Para tal, execute o seguinte comando:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>yum <span class="nt">-y</span> install epel-release centos-release-openshift-origin36</code></pre></figure>

<p>Em seguida, alguns pacotes adicionais:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>yum <span class="nt">-y</span> install origin origin-clients vim-enhanced atomic-openshift-utils </code></pre></figure>

<p>Agora o NetworkManager e o certificado:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>yum <span class="nt">-y</span> install NetworkManager python-rhsm-certificates</code></pre></figure>

<p>Com esses pacotes instalados, precisaremos iniciar o NetworkManager pois o OpenShift usa o NetworkManager para gerenciar as configurações de rede de todos os servidores no cluster:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>systemctl <span class="nb">enable </span>NetworkManager <span class="nt">--now</span></code></pre></figure>

<p>Posso dizer que a partir daquí já temos o OpenShift Origin instalado no servidor. No entanto, é necessário mais alguns passos afim de deixa-lo de fato “redondo”. Como por exemplo, temos que configurar a resolução do DNS nos dois servidores, precisamos preparar o servidor master, configurar o contêiner responsável pelo armazenamento de dados da aplicação, ativar e iniciar o docker nos nodes do OpenShift, e configurar o SELinux. Ou seja, bastante trabalho pela frente.</p>

<hr />

<h4 id="configurando-o-networkmanager">CONFIGURANDO O NETWORKMANAGER</h4>

<p>Como o DNS é usado pelo OpenShift para tudo, desde o tráfego criptografado até a comunicação entre os serviços implementados, a configuração do DNS nos nodes é essencial.</p>

<blockquote>
  <p>NOTA: Estas etapas se aplicam somente se você estiver usando o <strong><a href="">nip.io</a></strong> para seus hostnames.</p>
</blockquote>

<p>Vamos então editar o  client DNS do CentOs através do arquivo <code class="highlighter-rouge">/etc/resolv.conf</code>, que foi gerado quando instalamos o NetworkManager. O parâmetro <code class="highlighter-rouge">nameserver</code> se refere ao servidor DNS do qual seu servidor irá se conectar. Você pode ter até três parâmetros <code class="highlighter-rouge">nameserver</code> listados no resolv.conf.</p>

<p>O outro parâmetro padrão do <code class="highlighter-rouge">resolv.conf</code>, é o <code class="highlighter-rouge">search</code>. O valor do <code class="highlighter-rouge">search</code> é usado para qualquer consulta no DNS que não seja FQDN. Isto é, nome de domínio completo. Os FQDNs são registros DNS completos - isso significa que um FQDN contém um hostname, e um domínio de nível superior.</p>

<p>Caso não esteja familiarizado com a abreviação FQDN,  acesse <strong><a href="https://wikibase.adentrocloud.com.br/index.php?rp=/knowledgebase/63/Fully-Qualified-Domain-Name-FQDN-e-Hostname.html">https://wikibase.adentrocloud.com.br/index.php?rp=/knowledgebase/63/Fully-Qualified-Domain-Name-FQDN-e-Hostname.html</a></strong> para saber mais.</p>

<p>Usando o domínio <strong><a href="">nip.io</a></strong>, perceba que cada octeto no endereço IP é separado por um período. Isso significa que cada número no endereço IP é um nível no domínio sendo o <strong><a href="">nip.io</a></strong> de nível superior. Devido a algumas configurações que o OpenShift adiciona a cada contêiner, isso pode causar confusão ao extrair imagens de nosso <strong><a href="">registro intergrado</a></strong>. Sendo assim, o recomendado é editar o parâmetro <code class="highlighter-rouge">search</code> para ter apenas o domínio de nível superior (no caso, <strong><a href="">nip.io</a></strong>), conforme mostrado seguir:</p>

<p>Editando o <code class="highlighter-rouge">/etc/resolv.conf</code>:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Generated by NetworkManager</span>
search nip.io
nameserver 8.8.8.8</code></pre></figure>

<p>Esta configuração, no entanto, só permanecerá assim até você reiniciar os servidores. Isso ocorre porque o NetworkManager controla o <code class="highlighter-rouge">/etc/resolv.conf</code> e naturalmente adicionará ao parâmetro <code class="highlighter-rouge">search</code> que retornará o valor anterior à reset da máquina. Para impedir que isso aconteça, você precisa configurar o NetworkManager para não fazer mais alterações no <code class="highlighter-rouge">/etc/resolv.conf</code>. No CentOS 7, o arquivo de configuração do NetworkManager está localizado em <code class="highlighter-rouge">/etc/NetworkManager/NetworkManager.conf</code>.</p>

<p>Exemplo do <code class="highlighter-rouge">/etc/NetworkManager/NetworkManager.conf</code> padrão:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Configuration file for NetworkManager.</span>
<span class="c">#</span>
<span class="c"># See "man 5 NetworkManager.conf" for details.</span>
<span class="c">#</span>
<span class="c"># The directory /etc/NetworkManager/conf.d/ can contain additional configuration</span>
<span class="c"># snippets. Those snippets override the settings from this main file.</span>
<span class="c">#</span>
<span class="c"># The files within conf.d/ directory are read in asciibetical order.</span>
<span class="c">#</span>
<span class="c"># If two files define the same key, the one that is read afterwards will overwrite</span>
<span class="c"># the previous one.</span>

<span class="o">[</span>main]
<span class="nv">plugins</span><span class="o">=</span>ifcfg-rh
<span class="o">[</span>logging]
<span class="c">#level=DEBUG</span>
<span class="c">#domains=ALL</span></code></pre></figure>

<p>Você precisa adicionar uma linha à seção <code class="highlighter-rouge">[main]</code> para que o NetworkManager não altere o arquivo <code class="highlighter-rouge">/etc/resolv.conf</code>. Desta maneira:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="o">[</span>main]
<span class="nv">plugins</span><span class="o">=</span>ifcfg-rh
<span class="nv">dns</span><span class="o">=</span>none</code></pre></figure>

<p>Depois que você reiniciar o NetworkManager, a alteração feita no <code class="highlighter-rouge">/etc/resolv.conf</code> persistirá nas reinicializações do servidor. Para reiniciar o NetworkManager, execute o seguinte comando systemctl:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>systemctl restart NetworkManager</code></pre></figure>

<p>Depois de concluído, confirme se o NetworkManager está sendo executado usando o status do systemctl:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">systemctl status NetworkManager
? NetworkManager.service - Network Manager
Loaded: loaded <span class="o">(</span>/usr/lib/systemd/system/NetworkManager.service<span class="p">;</span> enabled<span class="p">;</span>
➥ vendor preset: enabled<span class="o">)</span>
Active: active <span class="o">(</span>running<span class="o">)</span> Because Sat 2017-05-13 17:05:12 EDT<span class="p">;</span> 6s ago
...</code></pre></figure>

<p>Pós reiniciar o NetworkManager, confira se de fato o arquivo <code class="highlighter-rouge">/etc/resolv.conf</code> foi alterado. Se não houver o parâmetro <code class="highlighter-rouge">search</code>, tudo estará como deveria, e você estará pronto para seguir em frente. Agora vamos configurar um software específico para os servidores master e o node.</p>

<div>
<style media="screen" type="text/css">

pre.att {
    font-size: 1em;
    line-height: 1.5em;
    font-family: "Courier New",Courier,monospace;
    overflow: auto;
    width: 100%;
    position: relative;
    background: #eee;
    padding: .75em;
    margin: 1.5em 0 1.5em 0;
    -moz-border-radius: .3em;
    -webkit-border-radius: .3em;
    border-radius: .3em;
    white-space: pre-wrap;
    border-radius: 8px;
    text-align: justify;
}
</style>

<pre class="att">
<strong>PARA SABER MAIS ----------- </strong> 
<strong>Uma visão mais aprofundada dos subdomínios curinga e do OpenShift:</strong>

O domínio usar precisará apontar para o servidor do node. Isso ocorre porque o OpenShift usa o <strong><a href="">HAProxy</a></strong> para rotear o tráfego corretamente entre seu DNS, e os contêineres apropriados. O <strong><a href="">HAProxy</a></strong> é um balanceador de carga popular, software livre. No OpenShift, ele é executado em um contêiner e em um host específico em seu cluster.

Tratando-se de DNS, ter um domínio curinga significa que qualquer host desse domínio apontará automaticamente para o mesmo endereço IP. Vamos ver alguns exemplos. Primeiro, aqui está um domínio curinga real que configuramos em um domínio:

$ dig +short *.apps.jeduncan.com
12.207.21.2

Observe que se você procurar qualquer outro registro terminado em .apps.jeduncan.com, e ele retornará o mesmo IP:

$ dig +short app1.apps.jeduncan.com
12.207.21.2

ou

$ dig +short someother.apps.jeduncan.com
12.207.21.2

O OpenShift usa a mesma lógica. Cada aplicativo um DNS que é membro do domínio curinga criado. Dessa forma, todas as entradas do DNS para seus aplicativos funcionam sem qualquer configuração adicional.
</pre>
</div>

<hr />

<h4 id="instalando-ferramentas-no-servidor-master">INSTALANDO FERRAMENTAS NO SERVIDOR MASTER</h4>

<p>Vários pacotes precisam ser instalados apenas no servidor master. O processo de instalação do OpenShift é escrito usando o Ansible. 
Para instalar o OpenShift, você criará um arquivo de configuração escrito em YAML. Esse arquivo será lido pelo mecanismo Ansible para implementar o OpenShift exatamente como deve ser. Criaremos um arquivo de configuração relativamente simples.</p>

<p>Para instalações mais elaboradas, existe uma documentação em <strong><a href="https://docs.openshift.com/container-platform/3.6/install_config/install/advanced_install.html">https://docs.openshift.com/container-platform/3.6/install_config/install/advanced_install.html</a></strong>.</p>

<p>O instalador do OpenShift é escrito e testado em relação a uma versão específica do Ansible. Isso significa que você precisa verificar se a versão do Ansible está instalada no seu servidor master.</p>

<blockquote>
  <p>NOTA: Precisamos nos preocupar apenas com Ansible no servidor master. Isso porque não há agente nos nodes. O Ansible não usa um agente nos sistemas que está controlando; em vez disso, ele usa o SSH como um mecanismo de transporte e para executar comandos remotos.</p>
</blockquote>

<p>Inicie este processo executando o seguinte comando yum:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>yum <span class="nt">-y</span> install httpd-tools gcc python-devel python-pip</code></pre></figure>

<p>O pacote python-pip instala o gerenciador de pacotes de aplicativos Python chamado pip. Ele é usado para instalar aplicativos escritos em Python e disponíveis no Índice de pacotes do Python (www.pypi.org). Com pip instalado, você pode usá-lo para instalar o Ansible e garantir que você instale a versão 2.2.2.0, que é a usada com o OpenShift 3.6:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">pip <span class="nt">-v</span> install <span class="nv">ansible</span><span class="o">==</span>2.2.2.0</code></pre></figure>

<p>Para que o instalador do OpenShift funcione corretamente, você precisa criar um par de chaves SSH no seu servidor master e distribuir a chave pública para o seu node. Para criar um novo par de chaves SSH em seu servidor master, você pode usar o comando <code class="highlighter-rouge">ssh-keygen</code> como neste exemplo:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>ssh-keygen <span class="nt">-f</span> /root/.ssh/id_rsa <span class="nt">-t</span> rsa <span class="nt">-N</span> <span class="s1">''</span></code></pre></figure>

<p>Esse comando cria um par de chaves SSH no diretório inicial do usuário <code class="highlighter-rouge">/root</code>, na subpasta <code class="highlighter-rouge">.ssh</code>. No Linux, esse é o local padrão para as chaves SSH de um usuário. Em seguida, execute o seguinte comando <code class="highlighter-rouge">ssh-copy-id</code> para distribuir sua chave pública SSH recém-criada para o seu node OpenShift (se você usou endereços IP diferentes para seu mestre e node, ajuste o comando de acordo):</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="k">for </span>i <span class="k">in </span>192.168.100.1 192.168.100.2<span class="p">;</span><span class="k">do </span>ssh-copy-id root@<span class="nv">$i</span><span class="p">;</span><span class="k">done</span></code></pre></figure>

<p>Este comando adicionará a chave pública SSH ao arquivo authorized_keys em <code class="highlighter-rouge">/root/.ssh</code> no node OpenShift. Isso permitirá que o instalador do OpenShift se conecte ao master e ao node para executar as etapas de instalação.</p>

<p>Os requisitos de software para os nodes são um pouco diferentes. A maior diferença, é que é no node que é onde o docker será instalado. O pacote <code class="highlighter-rouge">libcgroup-tools</code> fornece utilitários que você usará para inspecionar como os aplicativos são isolados usando grupos de controle de kernel. Para instalar esses pacotes, execute o seguinte comando yum:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>yum <span class="nt">-y</span> install docker libcgroup-tools</code></pre></figure>

<p>A partir daquí, estaremos prontos para configurar o contêiner de armazenamento de dados do OpenShift.</p>

<hr />

<h4 id="configurando-conteiner-storage">CONFIGURANDO CONTEINER STORAGE</h4>

<p>Um aplicativo chamado <code class="highlighter-rouge">docker-storage-setup</code> configura o armazenamento desejado para o Docker usar quando ele cria contêineres para o OpenShift.</p>

<blockquote>
  <p>NOTA: Neste artigo estou usando uma configuração de gerenciamento baseado no volume lógico (LVM). Esta configuração cria um volume LVM para cada contêiner sob demanda.</p>
</blockquote>

<p>Inicialmente, eles são pequenos, mas podem crescer até o tamanho máximo configurado no OpenShift para seus contêineres. Você pode encontrar detalhes adicionais sobre a configuração de armazenamento na documentação do OpenShift em <strong><a href="https://goo.gl/knBqkk">https://goo.gl/knBqkk</a></strong>.</p>

<p>A primeira etapa desse processo é criar um arquivo de configuração para o <code class="highlighter-rouge">docker-storage-setup</code> em seu nó OpenShift. O disco especificado em <code class="highlighter-rouge">/etc/sysconfig/docker-storage-setup</code> é o segundo disco que você criou para sua VM.</p>

<blockquote>
  <p>NOTA: Dependendo da sua distribuição Linux, o nome do particionamento de disco <code class="highlighter-rouge">/dev /vdb em nosso exemplo</code> pode variar, mas a operação não.</p>
</blockquote>

<p>Criando o arquivo de configuração do <code class="highlighter-rouge">docker-storage-setup</code>:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/sysconfig/docker-storage-setup
DEVS=/dev/vdb # /dev/vdb é o volume de 20 GB que você criou para os nodes.
VG=docker-vg
EOF</span></code></pre></figure>

<blockquote>
  <p>NOTA: Se você não tiver certeza sobre o nome do disco a ser usado para o armazenamento em contêiner, o comando <code class="highlighter-rouge">lsblk</code> fornecerá uma lista de todos os discos em seu servidor. A saída está em um diagrama de árvore fácil de entender.</p>
</blockquote>

<p>Depois de criar o arquivo <code class="highlighter-rouge">/etc/sysconfig/docker-storage-setup</code>, execute o <code class="highlighter-rouge">docker-storage-setup</code> que deverá gerar uma saída parecida com esta:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">docker-storage-setup

Checking that no-one is using this disk right now ...
OK
Disk /dev/vdb: 41610 cylinders, 16 heads, 63 sectors/track
...
Rounding up size to full physical extent 24.00 MiB
Logical volume <span class="s2">"docker-pool"</span> created.
Logical volume docker-vg/docker-pool changed.</code></pre></figure>

<p>Com o contêiner storage configurado, é hora de iniciar o serviço do docker no node do OpenShift. Observe que este é o tempo de execução médio que os serviços irão iniciar daquí em diante usando o OpenShift:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>systemctl <span class="nb">enable </span>docker.service <span class="nt">--now</span></code></pre></figure>

<p>Agora verifique se o serviço docker iniciou corretamente:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>systemctl status docker</code></pre></figure>

<p>A saída esperada do comando acima, será algo semelhante a isto:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">? docker.service - Docker Application Container Engine
Loaded: loaded <span class="o">(</span>/usr/lib/systemd/system/docker.service<span class="p">;</span> enabled<span class="p">;</span> vendor preset: disabled<span class="o">)</span>
Drop-In: /etc/systemd/system/docker.service.d
??custom.conf
Active: active <span class="o">(</span>running<span class="o">)</span> since Fri 2017-11-10 18:45:12 UTC<span class="p">;</span> 12 secs ago
Docs: http://docs.docker.com
Main PID: 2352 <span class="o">(</span>dockerd-current<span class="o">)</span>
Memory: 121.4M
CGroup: /system.slice/docker.service</code></pre></figure>

<p>O próximo passo é modificar o <strong><a href="">SELinux</a></strong> para permitir que o OpenShift se conecte ao <strong><a href="">NFS</a></strong> como uma fonte de armazenamento persistente.</p>

<hr />

<h3 id="wip---continua">WIP - Continua…</h3>

<h4 id="acessando-seu-cluster-e-efetuando-login">ACESSANDO SEU CLUSTER E EFETUANDO LOGIN</h4>

<p>Existem três maneiras de interagir com o OpenShift: por linha de comando, por interface web e pela <strong><a href="">API RESTful</a></strong>. Quase todas as ações no OpenShift podem ser realizadas usando os três métodos de acesso.</p>

<p>Antes de começar a usar o OpenShift de fato, é importar ressaltar que existe uma maneira mais fácil de testar esta tecnologia usando o <strong><a href="https://github.com/minishift/minishift">Minishift</a></strong> que funciona <strong><a href="">all in one</a></strong>. Isto é, tudo em uma coisa só. Para desenvolvimento é ótimo pois você conseguirá levantar o ambiente com bastante praticidade em uma máquina virtual simples, rodando em seu laptop. No entanto, se o seu objetivo for mais refinado, certamente que terá problemas quando começar a trabalhar com armazenamento persistente, métricas, deployments complexos de aplicativos e redes.</p>

<p>Montar um ambiente do zero é um aprendizado bastante rico e te encorajo a faze-lo. Para facilitar um pouco mais na montagem dos ambientes, irei compartilhar a maneira automatizada de montagem de um ambiente OpenShifit usando o <strong><a href="">Ansible</a></strong> para obter o mesmo resultado.</p>

<p>No OpenShift, toda ação requer autenticação. Isso permite que todas as ações sejam regidas pelas regras de segurança e acesso configuradas para todos os usuários em um cluster. Por padrão, a configuração inicial do OpenShift é definida para permitir que qualquer combinação de usuário e senha combinação para efetuar login.</p>

<p>Esta configuração inicial é chamada de <strong><a href="">Allow All identity provider</a></strong>. Isto é, cada nome de usuário é exclusivo e a senha pode ser qualquer coisa, exceto um campo vazio. Essa configuração é segura e recomendada apenas para configurações para estudo de implementação (nosso caso).</p>

<p>O primeiro usuário que você criar será chamado <strong>fulano</strong>. Este usuário representará um usuário final do OpenShift.</p>

<blockquote>
  <p>NOTA: Este método de autenticação é sensível a maiúsculas e minúsculas. Embora as senhas possam ser qualquer coisa, fulano e Fulano são usuários diferentes.</p>
</blockquote>

<p>Usando a linha de comando, execute o comando <code class="highlighter-rouge">oc login</code>, usando <strong>fulano</strong> para o nome de usuário e senha e o URL para o servidor de API do servidor master. Abaixo a sintaxe para efetuar login incluindo o nome de usuário, a senha e a URL para o OpenShift Master API server:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>oc login <span class="nt">-u</span> fulano <span class="nt">-p</span> fulano https://ocp-1.192.168.122.100.nip.io:8443</code></pre></figure>

<p>``</p>

	<div id="disqus_thread"></div>
	<script>

		(function() { // DON'T EDIT BELOW THIS LINE
			var d = document, s = d.createElement('script');
			s.src = 'https://lobocode.disqus.com/embed.js';
			s.setAttribute('data-timestamp', +new Date());
			(d.head || d.body).appendChild(s);
		})();
	</script>
	<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

	<script id="dsq-count-scr" src="//lobocode.disqus.com/count.js" async></script>
</div>

        </div>
      </div>

      <div id="footer">
        <ul id="social">
          <li>
            <a href="http://github.com/lobocode" target="_blank"
               title="Cozinhando mentes no @ Github">
              <i class="entypo-social-github"></i>
            </a>
          </li>
          <li>
            <a href="http://twitter.com/loboc0de" target="_blank"
               title="Meu quase não habitado Twitter">
              <i class="entypo-social-twitter"></i>
            </a>
          </li>
          <li>
            <a href="https://www.linkedin.com/in/vitor-lobo-65797a50/" target="_blank"
               title="Meu profile no Linkedin">
              <i class="entypo-social-linkedin"></i>
            </a>
          </li>
		  <li>
			  <a href="https://open.spotify.com/user/gjmxxg63wjmepkagtcewdctb8/playlist/0DIqzweSNRZXg9adwFt35X" target="_blank"
               title="Minha playlist no spotify">
              <i class="entypo-social-spotify"></i>
            </a>
          </li>
        </ul>
        <div id="meta-info">
          Fontes usadas <a href="http://www.google.com/fonts/">Google Fonts</a> &amp;
          <a href="http://entypo.com/">Entypo</a>
          <br><br>
          <a rel="license" href="http://creativecommons.org/licenses/by/3.0/deed.en_GB"><img alt="Creative Commons Licence" style="border-width:0" src="http://i.creativecommons.org/l/by/3.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/3.0/deed.en_GB">Creative Commons Attribution 3.0 Unported License</a>.
        </div>
      </div>

      <script src="/media/lib/main.js"></script>
      <script type="text/javascript">
        var _gaq = _gaq || []
        _gaq.push(['_setAccount', 'UA-15025032-4'])
        _gaq.push(['_trackPageview'])

        void function() {
          var ga   = document.createElement('script')
          ga.type  = 'text/javascript'
          ga.async = true
          ga.src   = ('https:' == document.location.protocol? 'https://ssl'
                   : 'http://www') + '.google-analytics.com/ga.js'
          var s    = document.getElementsByTagName('script')[0]
          s.parentNode.insertBefore(ga, s)
        }()
      </script>
    </body>
</html>
